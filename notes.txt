Sharing when internal representations may different between agents.
That is, can not just take the average parameters and get a good agent.

1) Selection
	Select the best agents from the population after testing.
	Number selected will be a parameter.
	Should somehow encourage variety in the selected group.
	Duplicated agents should be modified slightly from the original.
	
2) Partition
	Maintain an agent selection neural net.  Input nodes = the state variables and actions, outputs = 1 for each agent.  The output values are the expected squared error for using that agent to calculate the Q-value for current state and action.
	Best action will be determined by first checking the agent selection net for the best agent (lowest output from the agent-selection net), then using that agent to determine the best action.
	Agent-selection net will be modified during learning as follows:
		All agents will predict the Q value for the current state and action.
		After taking an action, the squared error will be calculated for each agent, and that represents the target values for the agent-selection net and is used to train it with back-propagation.
	The learning of weights for the normal net should be modified to reduce the learning on nets that have high error rates for current state/action.  Something like multiply the alpha value by the ratio of that agent's expected squared error divided by the sum of all agents expected squared error.  Or have a certain number of agents that will be trained on the each time step and chose the agents with the lowest expected error for training.
	
3) Use an ensemble approach to combine the results of multiple agents
	